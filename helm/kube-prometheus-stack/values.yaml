---
crds:
  enabled: true
  upgradeJob:
    enabled: true
    # Conflicts with ArgoCD, force it, ArgoCD will fix it later
    forceConflicts: true

sidecar:
  dashboards:
    enabled: true

grafana:
  enabled: true
  defaultDashboardsTimezone: Europe/Rome

  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: default
          orgId: 1
          folder: ""
          type: file
          disableDeletion: true
          editable: false
          options:
            path: /var/lib/grafana/dashboards/default

  dashboards:
    default:
      cloudnative-pg:
        gnetId: 20417
        revision: 4
        datasource: Prometheus
      smartctl-exporter:
        url: "https://raw.githubusercontent.com/blesswinsamuel/grafana-dashboards/refs/heads/main/dashboards/dist/dashboards/smartctl.json"
        datasource: Prometheus
      velero:
        gnetId: 16829
        revision: 5
        datasource: Prometheus
      kubernetes-views-global:
        gnetId: 15757
        revision: 43
        datasource: Prometheus
      longhorn:
        gnetId: 16888
        revision: 9
        datasource: Prometheus
      node-exporter-temperature:
        gnetId: 15202
        revision: 1
        datasource: Prometheus

prometheusOperator:
  tls:
    enabled: false
  admissionWebhooks:
    enabled: false

prometheus:
  enabled: true

  prometheusSpec:
    ## If true, a nil or {} value for prometheus.prometheusSpec.serviceMonitorSelector will cause the
    ## prometheus resource to be created with selectors based on values in the helm deployment,
    ## which will also match the servicemonitors created
    serviceMonitorSelectorNilUsesHelmValues: false

    ## If true, a nil or {} value for prometheus.prometheusSpec.podMonitorSelector will cause the
    ## prometheus resource to be created with selectors based on values in the helm deployment,
    ## which will also match the podmonitors created
    podMonitorSelectorNilUsesHelmValues: false

    ## External URL at which Prometheus will be reachable.
    ##
    externalUrl: "https://prometheus.kalexlab.xyz"

    storageSpec:
      volumeClaimTemplate:
        metadata:
          name: prometheus-data-pvc
        spec:
          storageClassName: longhorn
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 50Gi

    thanosService:
      enabled: true

    thanosServiceMonitor:
      enabled: true

alertmanager:
  enabled: true
  config:
    global:
      resolve_timeout: 5m

    route:
      receiver: "null"
      routes:
        - match:
            severity: "critical"
          receiver: "telegram"
          group_by: ["alertname", "severity"]
          group_wait: 30s
          group_interval: 5m
          repeat_interval: 24h

coreDns:
  # Service exposed by coreDns itself, appears to not be working otherwise
  service:
    selector:
      app.kubernetes.io/name: coredns

kubeEtcd:
  # Control plane virtual IP from talos/machine/vip.yaml and talos/talenv.prod.yaml
  endpoints:
    - 192.168.10.9

  service:
    enabled: true
    port: 2381
    targetPort: 2381

kubeProxy:
  enabled: false

defaultRules:
  disabled:
    KubeProxyDown: true

additionalPrometheusRulesMap:
  rules:
    groups:
      - name: SmartctlExporter
        rules:
          - alert: SmartDeviceTemperatureWarning
            expr: '(avg_over_time(smartctl_device_temperature{temperature_type="current"} [5m]) unless on (instance, device) smartctl_device_temperature{temperature_type="drive_trip"}) > 60'
            for: 0m
            labels:
              severity: warning
            annotations:
              summary: SMART device temperature warning (instance {{ $labels.instance }})
              description: "Device temperature warning on {{ $labels.instance }} drive {{ $labels.device }} over 60°C\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: SmartDeviceTemperatureCritical
            expr: '(max_over_time(smartctl_device_temperature{temperature_type="current"} [5m]) unless on (instance, device) smartctl_device_temperature{temperature_type="drive_trip"}) > 70'
            for: 0m
            labels:
              severity: critical
            annotations:
              summary: SMART device temperature critical (instance {{ $labels.instance }})
              description: "Device temperature critical on {{ $labels.instance }} drive {{ $labels.device }} over 70°C\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: SmartDeviceTemperatureOverTripValue
            expr: 'max_over_time(smartctl_device_temperature{temperature_type="current"} [10m]) >= on(device, instance) smartctl_device_temperature{temperature_type="drive_trip"}'
            for: 0m
            labels:
              severity: critical
            annotations:
              summary: SMART device temperature over trip value (instance {{ $labels.instance }})
              description: "Device temperature over trip value on {{ $labels.instance }} drive {{ $labels.device }})\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: SmartDeviceTemperatureNearingTripValue
            expr: 'max_over_time(smartctl_device_temperature{temperature_type="current"} [10m]) >= on(device, instance) (smartctl_device_temperature{temperature_type="drive_trip"} * .80)'
            for: 0m
            labels:
              severity: warning
            annotations:
              summary: SMART device temperature nearing trip value (instance {{ $labels.instance }})
              description: "Device temperature at 80% of trip value on {{ $labels.instance }} drive {{ $labels.device }})\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: SmartStatus
            expr: "smartctl_device_smart_status != 1"
            for: 0m
            labels:
              severity: critical
            annotations:
              summary: SMART status (instance {{ $labels.instance }})
              description: "Device has a SMART status failure on {{ $labels.instance }} drive {{ $labels.device }})\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: SmartCriticalWarning
            expr: "smartctl_device_critical_warning > 0"
            for: 0m
            labels:
              severity: critical
            annotations:
              summary: SMART critical warning (instance {{ $labels.instance }})
              description: "Disk controller has critical warning on {{ $labels.instance }} drive {{ $labels.device }})\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: SmartMediaErrors
            expr: "smartctl_device_media_errors > 0"
            for: 0m
            labels:
              severity: critical
            annotations:
              summary: SMART media errors (instance {{ $labels.instance }})
              description: "Disk controller detected media errors on {{ $labels.instance }} drive {{ $labels.device }})\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: SmartWearoutIndicator
            expr: "smartctl_device_available_spare < smartctl_device_available_spare_threshold"
            for: 0m
            labels:
              severity: critical
            annotations:
              summary: SMART Wearout Indicator (instance {{ $labels.instance }})
              description: "Device is wearing out on {{ $labels.instance }} drive {{ $labels.device }})\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

      - name: NodeExporter
        rules:
          - alert: HostOutOfMemory
            expr: "(node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes < .10)"
            for: 2m
            labels:
              severity: warning
            annotations:
              summary: Host out of memory (instance {{ $labels.instance }})
              description: "Node memory is filling up (< 10% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostMemoryUnderMemoryPressure
            expr: "(rate(node_vmstat_pgmajfault[5m]) > 1000)"
            for: 0m
            labels:
              severity: warning
            annotations:
              summary: Host memory under memory pressure (instance {{ $labels.instance }})
              description: "The node is under heavy memory pressure. High rate of loading memory pages from disk.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostMemoryIsUnderutilized
            expr: "min_over_time(node_memory_MemFree_bytes[1w]) > node_memory_MemTotal_bytes * .8"
            for: 0m
            labels:
              severity: info
            annotations:
              summary: Host Memory is underutilized (instance {{ $labels.instance }})
              description: "Node memory usage is < 20% for 1 week. Consider reducing memory space. (instance {{ $labels.instance }})\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostUnusualNetworkThroughputIn
            expr: "((rate(node_network_receive_bytes_total[5m]) / on(instance, device) node_network_speed_bytes) > .80)"
            for: 0m
            labels:
              severity: warning
            annotations:
              summary: Host unusual network throughput in (instance {{ $labels.instance }})
              description: "Host receive bandwidth is high (>80%).\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostUnusualNetworkThroughputOut
            expr: "((rate(node_network_transmit_bytes_total[5m]) / on(instance, device) node_network_speed_bytes) > .80)"
            for: 0m
            labels:
              severity: warning
            annotations:
              summary: Host unusual network throughput out (instance {{ $labels.instance }})
              description: "Host transmit bandwidth is high (>80%)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostUnusualDiskReadRate
            expr: "(rate(node_disk_io_time_seconds_total[5m]) > .80)"
            for: 0m
            labels:
              severity: warning
            annotations:
              summary: Host unusual disk read rate (instance {{ $labels.instance }})
              description: "Disk is too busy (IO wait > 80%)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostOutOfDiskSpace
            expr: '(node_filesystem_avail_bytes{fstype!~"^(fuse.*|tmpfs|cifs|nfs)"} / node_filesystem_size_bytes < .10 and on (instance, device, mountpoint) node_filesystem_readonly == 0)'
            for: 2m
            labels:
              severity: critical
            annotations:
              summary: Host out of disk space (instance {{ $labels.instance }})
              description: "Disk is almost full (< 10% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostDiskMayFillIn24Hours
            expr: 'predict_linear(node_filesystem_avail_bytes{fstype!~"^(fuse.*|tmpfs|cifs|nfs)"}[3h], 86400) <= 0 and node_filesystem_avail_bytes > 0'
            for: 2m
            labels:
              severity: warning
            annotations:
              summary: Host disk may fill in 24 hours (instance {{ $labels.instance }})
              description: "Filesystem will likely run out of space within the next 24 hours.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostOutOfInodes
            expr: "(node_filesystem_files_free / node_filesystem_files < .10 and ON (instance, device, mountpoint) node_filesystem_readonly == 0)"
            for: 2m
            labels:
              severity: critical
            annotations:
              summary: Host out of inodes (instance {{ $labels.instance }})
              description: "Disk is almost running out of available inodes (< 10% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostFilesystemDeviceError
            expr: 'node_filesystem_device_error{fstype!~"^(fuse.*|tmpfs|cifs|nfs)"} == 1'
            for: 2m
            labels:
              severity: critical
            annotations:
              summary: Host filesystem device error (instance {{ $labels.instance }})
              description: "Error stat-ing the {{ $labels.mountpoint }} filesystem\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostInodesMayFillIn24Hours
            expr: 'predict_linear(node_filesystem_files_free{fstype!~"^(fuse.*|tmpfs|cifs|nfs)"}[1h], 86400) <= 0 and node_filesystem_files_free > 0'
            for: 2m
            labels:
              severity: warning
            annotations:
              summary: Host inodes may fill in 24 hours (instance {{ $labels.instance }})
              description: "Filesystem will likely run out of inodes within the next 24 hours at current write rate\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostUnusualDiskReadLatency
            expr: "(rate(node_disk_read_time_seconds_total[1m]) / rate(node_disk_reads_completed_total[1m]) > 0.1 and rate(node_disk_reads_completed_total[1m]) > 0)"
            for: 2m
            labels:
              severity: warning
            annotations:
              summary: Host unusual disk read latency (instance {{ $labels.instance }})
              description: "Disk latency is growing (read operations > 100ms)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostUnusualDiskWriteLatency
            expr: "(rate(node_disk_write_time_seconds_total[1m]) / rate(node_disk_writes_completed_total[1m]) > 0.1 and rate(node_disk_writes_completed_total[1m]) > 0)"
            for: 2m
            labels:
              severity: warning
            annotations:
              summary: Host unusual disk write latency (instance {{ $labels.instance }})
              description: "Disk latency is growing (write operations > 100ms)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostHighCpuLoad
            expr: '1 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m]))) > .80'
            for: 10m
            labels:
              severity: warning
            annotations:
              summary: Host high CPU load (instance {{ $labels.instance }})
              description: "CPU load is > 80%\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostCpuIsUnderutilized
            expr: '(min by (instance) (rate(node_cpu_seconds_total{mode="idle"}[1h]))) > 0.8'
            for: 1w
            labels:
              severity: info
            annotations:
              summary: Host CPU is underutilized (instance {{ $labels.instance }})
              description: "CPU load has been < 20% for 1 week. Consider reducing the number of CPUs.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostCpuStealNoisyNeighbor
            expr: 'avg by(instance) (rate(node_cpu_seconds_total{mode="steal"}[5m])) * 100 > 10'
            for: 0m
            labels:
              severity: warning
            annotations:
              summary: Host CPU steal noisy neighbor (instance {{ $labels.instance }})
              description: "CPU steal is > 10%. A noisy neighbor is killing VM performances or a spot instance may be out of credit.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostCpuHighIowait
            expr: 'avg by (instance) (rate(node_cpu_seconds_total{mode="iowait"}[5m])) > .10'
            for: 0m
            labels:
              severity: warning
            annotations:
              summary: Host CPU high iowait (instance {{ $labels.instance }})
              description: "CPU iowait > 10%. Your CPU is idling waiting for storage to respond.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostUnusualDiskIo
            expr: "rate(node_disk_io_time_seconds_total[5m]) > 0.8"
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: Host unusual disk IO (instance {{ $labels.instance }})
              description: "Disk usage >80%. Check storage for issues or increase IOPS capabilities. Check storage for issues.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostSwapIsFillingUp
            expr: "((1 - (node_memory_SwapFree_bytes / node_memory_SwapTotal_bytes)) * 100 > 80)"
            for: 2m
            labels:
              severity: warning
            annotations:
              summary: Host swap is filling up (instance {{ $labels.instance }})
              description: "Swap is filling up (>80%)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostSystemdServiceCrashed
            expr: '(node_systemd_unit_state{state="failed"} == 1)'
            for: 0m
            labels:
              severity: warning
            annotations:
              summary: Host systemd service crashed (instance {{ $labels.instance }})
              description: "systemd service crashed\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostPhysicalComponentTooHot
            expr: "node_hwmon_temp_celsius > node_hwmon_temp_max_celsius"
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: Host physical component too hot (instance {{ $labels.instance }})
              description: "Physical hardware component too hot\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostNodeOvertemperatureAlarm
            expr: "((node_hwmon_temp_crit_alarm_celsius == 1) or (node_hwmon_temp_alarm == 1))"
            for: 0m
            labels:
              severity: critical
            annotations:
              summary: Host node overtemperature alarm (instance {{ $labels.instance }})
              description: "Physical node temperature alarm triggered\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostSoftwareRaidInsufficientDrives
            expr: '((node_md_disks_required - on(device, instance) node_md_disks{state="active"}) > 0)'
            for: 0m
            labels:
              severity: critical
            annotations:
              summary: Host software RAID insufficient drives (instance {{ $labels.instance }})
              description: "MD RAID array {{ $labels.device }} on {{ $labels.instance }} has insufficient drives remaining.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostSoftwareRaidDiskFailure
            expr: '(node_md_disks{state="failed"} > 0)'
            for: 2m
            labels:
              severity: warning
            annotations:
              summary: Host software RAID disk failure (instance {{ $labels.instance }})
              description: "MD RAID array {{ $labels.device }} on {{ $labels.instance }} needs attention.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostKernelVersionDeviations
            expr: "changes(node_uname_info[1h]) > 0"
            for: 0m
            labels:
              severity: info
            annotations:
              summary: Host kernel version deviations (instance {{ $labels.instance }})
              description: "Kernel version for {{ $labels.instance }} has changed.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostOomKillDetected
            expr: "(increase(node_vmstat_oom_kill[1m]) > 0)"
            for: 0m
            labels:
              severity: warning
            annotations:
              summary: Host OOM kill detected (instance {{ $labels.instance }})
              description: "OOM kill detected\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostEdacCorrectableErrorsDetected
            expr: "(increase(node_edac_correctable_errors_total[1m]) > 0)"
            for: 0m
            labels:
              severity: info
            annotations:
              summary: Host EDAC Correctable Errors detected (instance {{ $labels.instance }})
              description: "Host {{ $labels.instance }} has had {{ printf \"%.0f\" $value }} correctable memory errors reported by EDAC in the last 5 minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostEdacUncorrectableErrorsDetected
            expr: "(node_edac_uncorrectable_errors_total > 0)"
            for: 0m
            labels:
              severity: warning
            annotations:
              summary: Host EDAC Uncorrectable Errors detected (instance {{ $labels.instance }})
              description: "Host {{ $labels.instance }} has had {{ printf \"%.0f\" $value }} uncorrectable memory errors reported by EDAC in the last 5 minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostNetworkReceiveErrors
            expr: "(rate(node_network_receive_errs_total[2m]) / rate(node_network_receive_packets_total[2m]) > 0.01)"
            for: 2m
            labels:
              severity: warning
            annotations:
              summary: Host Network Receive Errors (instance {{ $labels.instance }})
              description: "Host {{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf \"%.0f\" $value }} receive errors in the last two minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostNetworkTransmitErrors
            expr: "(rate(node_network_transmit_errs_total[2m]) / rate(node_network_transmit_packets_total[2m]) > 0.01)"
            for: 2m
            labels:
              severity: warning
            annotations:
              summary: Host Network Transmit Errors (instance {{ $labels.instance }})
              description: "Host {{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf \"%.0f\" $value }} transmit errors in the last two minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostNetworkBondDegraded
            expr: "((node_bonding_active - node_bonding_slaves) != 0)"
            for: 2m
            labels:
              severity: warning
            annotations:
              summary: Host Network Bond Degraded (instance {{ $labels.instance }})
              description: "Bond \"{{ $labels.device }}\" degraded on \"{{ $labels.instance }}\".\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostConntrackLimit
            expr: "(node_nf_conntrack_entries / node_nf_conntrack_entries_limit > 0.8)"
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: Host conntrack limit (instance {{ $labels.instance }})
              description: "The number of conntrack is approaching limit\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostClockSkew
            expr: "((node_timex_offset_seconds > 0.05 and deriv(node_timex_offset_seconds[5m]) >= 0) or (node_timex_offset_seconds < -0.05 and deriv(node_timex_offset_seconds[5m]) <= 0))"
            for: 10m
            labels:
              severity: warning
            annotations:
              summary: Host clock skew (instance {{ $labels.instance }})
              description: "Clock skew detected. Clock is out of sync. Ensure NTP is configured correctly on this host.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

          - alert: HostClockNotSynchronising
            expr: "(min_over_time(node_timex_sync_status[1m]) == 0 and node_timex_maxerror_seconds >= 16)"
            for: 2m
            labels:
              severity: warning
            annotations:
              summary: Host clock not synchronising (instance {{ $labels.instance }})
              description: "Clock not synchronising. Ensure NTP is configured on this host.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
